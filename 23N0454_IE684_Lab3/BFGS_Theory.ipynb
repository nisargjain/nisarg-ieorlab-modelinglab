{"cells":[{"cell_type":"markdown","metadata":{"id":"nVE0Xoa0Q5wE"},"source":["$\\Large\\textbf{Lab 3.} \\large\\textbf{Exercise 3 Theory.}$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YVkab74DJsRL"},"source":["Recall that to solve problems of the form $\\min_{\\mathbf{x} \\in {\\mathbb{R}}^n} q(\\mathbf{x})$, the update rule involved in Newton's method is of the form:\n","\\begin{align}\n","\\mathbf{x}^{k+1} = \\mathbf{x}^{k} - \\eta^k (\\nabla^2 q(\\mathbf{x}^{k}))^{-1} \\nabla q(\\mathbf{x}^{k}).   \n","\\end{align}\n","\n","Now we will discuss a method which avoids explicit computation of the inverse of Hessian matrix at each iteration, but is nearly efficient as the Newton's method. This method will be called BFGS named after the famous applied Mathematicians Broyden, Fletcher, Goldfarb and Shanno.\n","\n","The main idea of BFGS method is to replace the inverse of Hessian matrix $(\\nabla^2 q(\\mathbf{x}^{k}))^{-1}$ in the update rule of Newton's method with a surrogate term $B^k$.\n","\n","Therefore the update rule of BFGS looks as follows:\n","\\begin{align}\n","\\mathbf{x}^{k+1} = \\mathbf{x}^{k} - \\eta^k B^k \\nabla q(\\mathbf{x}^{k})   \n","\\end{align}\n","where $B^k$ is a surrogate for the inverse of Hessian matrix.\n","\n","To find a suitable candidate for $B^k$, we need to consider some favorable characteristics expected from $B^k$:\n","\n","\\begin{align}\n","&B^k \\text{ is symmetric positive definite}.  \\\\\n","&B^k \\text{ does not involve computing Hessian or its inverse and should be computable only from the gradients}.  \\\\\n","&\\text{Replacing  } (\\nabla^2 q(\\mathbf{x}^{k}))^{-1} \\text{ with } B^k \\text{ should not slow down the algorithm too much}. \\\\\n","\\end{align}\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6L9tVzAnqyb-"},"source":["To design a suitable $B^k$ we shall consider the quadratic approximation of $q$:\n","\n","\\begin{align}\n","\\tilde{q}(\\mathbf{x}) = q(\\mathbf{x}^{k+1}) + \\left \\langle \\nabla q(\\mathbf{x}^{k+1}), \\mathbf{x}-\\mathbf{x}^{k+1}\\right \\rangle  + \\frac{1}{2} (\\mathbf{x}-\\mathbf{x}^{k+1})^\\top H^{k+1} (\\mathbf{x}-\\mathbf{x}^{k+1}).\n","\\end{align}\n","where $H^{k+1} = \\nabla^2 q({\\mathbf{x}}^{k+1})$.\n","\n","Note that using this quadratic approximation we have the gradient as:\n","\\begin{align}\n","\\nabla \\tilde{q}(\\mathbf{x}) = \\nabla q(\\mathbf{x}^{k+1}) + H^{k+1}(\\mathbf{x}-\\mathbf{x}^{k+1}).\n","\\end{align}\n","\n","In order to assume $\\tilde{q}$ to behave similar to $q$, we expect the following.\n","\n","By plugging in $\\mathbf{x} = \\mathbf{x}^k$ and $\\mathbf{x}=\\mathbf{x}^{k+1}$, we expect the following from the previous gradient equation:\n","\\begin{align}\n","\\nabla \\tilde{q} (\\mathbf{x}^k) = \\nabla q(\\mathbf{x}^k) \\text{ and }\\\\\n","\\nabla \\tilde{q} (\\mathbf{x}^{k+1}) = \\nabla q(\\mathbf{x}^{k+1}).\n","\\end{align}\n","\n","The relation $\\nabla \\tilde{q} (\\mathbf{x}^{k+1}) = \\nabla q(\\mathbf{x}^{k+1})$ directly follows from the gradient relation  $\\nabla \\tilde{q}(\\mathbf{x}) = \\nabla q(\\mathbf{x}^{k+1}) + H^{k+1}(\\mathbf{x}-\\mathbf{x}^{k+1})$.\n","\n","For the gradient relation to satisfy $\\nabla \\tilde{q} (\\mathbf{x}^k) = \\nabla q(\\mathbf{x}^k)$ we need:\n","\\begin{align}\n","\\nabla \\tilde{q} (\\mathbf{x}^k) &= \\nabla q(\\mathbf{x}^{k+1}) + H^{k+1}(\\mathbf{x}^{k}-\\mathbf{x}^{k+1}) = \\nabla q(\\mathbf{x}^k) \\\\\n","\\implies H^{k+1}(\\mathbf{x}^{k}-\\mathbf{x}^{k+1}) &= (\\nabla q(\\mathbf{x}^{k})- \\nabla {q} (\\mathbf{x}^{k+1})) \\\\\n","\\implies H^{k+1}(\\mathbf{x}^{k+1}-\\mathbf{x}^{k}) &= (\\nabla q(\\mathbf{x}^{k+1})- \\nabla {q} (\\mathbf{x}^k)).\n","\\end{align}\n","This previous equality is called the $\\textbf{secant equation}$.\n","\n","From the secant equation we see that inverse of $H^{k+1}$ operates on the difference of gradients $(\\nabla q(\\mathbf{x}^{k+1})- \\nabla {q} (\\mathbf{x}^k))$  to yield the difference of iterates $(\\mathbf{x}^{k+1}-\\mathbf{x}^{k})$.\n","\n","The secant equation can be equivalently and compactly written as:\n","\\begin{align}\n","(H^{k+1})^{-1} \\mathbf{y}^k = \\mathbf{s}^k.\n","\\end{align}\n","where $\\mathbf{y}^k = (\\nabla q(\\mathbf{x}^{k+1})- \\nabla {q} (\\mathbf{x}^k))$ and $\\mathbf{s}^k = (\\mathbf{x}^{k+1}-\\mathbf{x}^{k})$.\n","\n","We shall be considering $(H^{k+1})^{-1}$ as a possible choice for $B^{k+1}$ in the BFGS update rule.\n","\n","Hence we make sure that $(H^{k+1})^{-1}$ is positive definite. This is equivalent to considering:\n","\\begin{align}\n","(\\mathbf{y}^{k})^\\top (H^{k+1})^{-1} \\mathbf{y}^k > 0\n","\\end{align}\n","for any non-zero $\\mathbf{y}^k$ which implies that $(\\mathbf{y}^k)^\\top \\mathbf{s}^k > 0$.\n","\n","\n","Generally solving the secant equation $(H^{k+1})^{-1} \\mathbf{y}^k = \\mathbf{s}^k$ leads to infinitely many solutions for the matrix $(H^{k+1})^{-1}$ since there are $n^2$ unknowns and $n$ equations. Hence to select a suitable $(H^{k+1})^{-1}$ we solve an optimization problem of the form:\n","\n","\\begin{align}\n","\\min_H \\|H-(H^k)^{-1}\\| \\ s.t. \\ H=H^\\top, \\ H\\mathbf{y}^k=\\mathbf{s}^k.\n","\\end{align}\n","By using an appropriate norm in the optimization problem, we can get the following update rule for the matrix $(H^{k+1})^{-1} = (I-\\mu^k \\mathbf{s}^k (\\mathbf{y}^k)^\\top) (H^{k})^{-1} (I-\\mu^k \\mathbf{y}^k (\\mathbf{s}^k)^\\top) + \\mu^k \\mathbf{s}^k (\\mathbf{s}^k)^\\top$\n","\n","where $\\mu^k = \\frac{1}{(\\mathbf{y}^k)^\\top \\mathbf{s}^k}$.\n","\n","By taking $B^k = (H^k)^{-1}$, this update rule can now be written as:\n","\n","$B^{k+1} = (I-\\mu^k \\mathbf{s}^k (\\mathbf{y}^k)^\\top) B^{k} (I-\\mu^k \\mathbf{y}^k (\\mathbf{s}^k)^\\top) + \\mu^k \\mathbf{s}^k (\\mathbf{s}^k)^\\top$\n","\n","where $\\mu^k = \\frac{1}{(\\mathbf{y}^k)^\\top \\mathbf{s}^k}$.\n","\n","As long as $B^k$ is positive definite, the update rule guarantees that $B^{k+1}$ is also positive definite."]}],"metadata":{"colab":{"provenance":[{"file_id":"1w81NOFPiHAeclxb4qP_r4LT2YtD0LZxC","timestamp":1706367745957},{"file_id":"1JCSg8JRRPkIbs87lSf_N_TEpOUn8_8c5","timestamp":1706367449648},{"file_id":"1MX9-agQSktHflS7kG82RlHJV3pg_FPRI","timestamp":1675238530697},{"file_id":"1K_IezBrfRh6pwswXKWWG-r52uCYYEi8M","timestamp":1675100187172},{"file_id":"1gZLLDJVAJPlbgIJWemWdXuexWPJZvIDy","timestamp":1644389427399},{"file_id":"1rR2hAG8IjQffSln6a023O3BG5_wGtTOr","timestamp":1612938030154},{"file_id":"1sSRSvUjQo3KULtiHJ37bXdtLeZ3n7QvT","timestamp":1612936135472},{"file_id":"1HNo3g0DsHWFMRh9iep1KA2VPgW50skVQ","timestamp":1612901961256},{"file_id":"1nK-tJ7urfhVWUJR5aM6MhBXRrbaOVqS6","timestamp":1611696241895},{"file_id":"1t4p7yJ-lmmPgUlZiN6aIiODgzI1UODSW","timestamp":1611675612511},{"file_id":"1P8iC5GV63wBEi8t_itS_Iwv4BpQmzilY","timestamp":1611579811853},{"file_id":"1gvM0JQz4AGPQkD7HIebcsj56iE51pFEh","timestamp":1611499233093},{"file_id":"14EL8LRM-6nm3dOIBARno6evxWawc_KKQ","timestamp":1611121174166},{"file_id":"1uZoWaHBYOKpElICxZvAIwn-x3Coj4QAe","timestamp":1611085983298},{"file_id":"1EPZ8g76egSHuy2mW1l_BP5lOmf6_VCRk","timestamp":1610474953876}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}